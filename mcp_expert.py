#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import json
import logging
import time
import uuid
from typing import Dict, List, Any, Optional, Callable, AsyncGenerator
from openai import OpenAI
from config import QWEN_API_KEY
from mcp_tools import MCPToolRegistry, MCPToolResult
from datetime import datetime

logger = logging.getLogger(__name__)

class MCPExpert:
    """ç®€åŒ–çš„MCPä¸“å®¶LLMç³»ç»Ÿ"""
    
    def __init__(self, board_id: str):
        self.board_id = board_id
        self.session_id = f"expert_{board_id}_{uuid.uuid4().hex[:8]}"
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=QWEN_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        
        # å·¥å…·æ³¨å†Œä¸­å¿ƒ
        self.tool_registry = MCPToolRegistry(board_id)
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        # ç³»ç»Ÿé…ç½®
        self.max_iterations = 6  # æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
        self.max_processing_time = 180  # æœ€å¤§å¤„ç†æ—¶é—´
        
        # åˆ›å»ºç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._create_system_prompt()
        
        logger.info(f"MCPä¸“å®¶ç³»ç»Ÿå·²åˆå§‹åŒ–: {self.session_id}")
    
    def _create_system_prompt(self) -> str:
        """åˆ›å»ºç³»ç»Ÿæç¤ºè¯"""
        tools_description = self.tool_registry.get_tools_description()
        
        return f"""ä½ æ˜¯WhatNoteæ™ºèƒ½å­¦ä¹ åŠ©æ‰‹çš„ä¸“å®¶LLMï¼Œä¸“é—¨è´Ÿè´£å±•æ¿å†…çš„å­¦ä¹ åˆ†æå’Œå†…å®¹ç”Ÿæˆå·¥ä½œã€‚

## ğŸ¯ æ ¸å¿ƒèº«ä»½
- **ä¸“ä¸šå­¦ä¹ é¡¾é—®**ï¼šå¸®åŠ©ç”¨æˆ·æ·±åº¦ç†è§£PDFå­¦ä¹ ææ–™
- **å†…å®¹åˆ†æä¸“å®¶**ï¼šèƒ½å¤Ÿåˆ†æã€æ€»ç»“ã€æ³¨é‡ŠPDFå†…å®¹  
- **æ™ºèƒ½å·¥å…·è°ƒç”¨è€…**ï¼šç†Ÿç»ƒä½¿ç”¨å„ç§å·¥å…·å®Œæˆå¤æ‚ä»»åŠ¡

## ğŸ› ï¸ å¯ç”¨å·¥å…·
{tools_description}

## ğŸ“‹ å·¥ä½œåŸåˆ™
1. **ç†è§£ç”¨æˆ·éœ€æ±‚**ï¼šå‡†ç¡®ç†è§£ç”¨æˆ·è¦ä»€ä¹ˆ
2. **é€‰æ‹©åˆé€‚å·¥å…·**ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©æœ€ä½³å·¥å…·ç»„åˆ
3. **é€æ­¥æ‰§è¡Œ**ï¼šæŒ‰é€»è¾‘é¡ºåºè°ƒç”¨å·¥å…·
4. **æ•´åˆç»“æœ**ï¼šå°†å·¥å…·ç»“æœæ•´ç†æˆæœ‰ä»·å€¼çš„å›ç­”
5. **æä¾›å»ºè®®**ï¼šç»™å‡ºä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®

## ğŸ¯ ä¸»è¦ä»»åŠ¡
- åˆ†æPDFæ–‡æ¡£å†…å®¹å’Œç»“æ„
- ç”Ÿæˆå’Œæ”¹è¿›é¡µé¢æ³¨é‡Š
- åˆ›å»ºå­¦ä¹ ç¬”è®°å’Œæ€»ç»“
- å›ç­”åŸºäºæ–‡æ¡£çš„é—®é¢˜
- ç®¡ç†å±•æ¿çª—å£å’Œå†…å®¹
- æœç´¢å’Œå®šä½å…³é”®ä¿¡æ¯

å±•æ¿ID: {self.board_id}
è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œæ™ºèƒ½åœ°ä½¿ç”¨å·¥å…·ï¼Œæä¾›ä¸“ä¸šçš„å­¦ä¹ åˆ†ææœåŠ¡ã€‚"""

    async def process_query(self, user_query: str, status_callback: Optional[Callable] = None) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        start_time = time.time()
        
        if status_callback:
            await status_callback("ğŸš€ å¯åŠ¨ä¸“å®¶åˆ†æç³»ç»Ÿ...")
        
        # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "user",
            "content": user_query
        })
        
        iteration = 0
        
        while iteration < self.max_iterations:
            # æ£€æŸ¥è¶…æ—¶
            if time.time() - start_time > self.max_processing_time:
                if status_callback:
                    await status_callback("â° å¤„ç†è¶…æ—¶ï¼Œè¿”å›å½“å‰ç»“æœ")
                break
            
            iteration += 1
            
            if status_callback:
                await status_callback(f"ğŸ¤” ç¬¬{iteration}è½®åˆ†æ...")
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": self.system_prompt}]
            messages.extend(self.conversation_history)
            
            # è·å–å·¥å…·å®šä¹‰
            tools = self.tool_registry.get_openai_tools()
            
            try:
                # è°ƒç”¨LLM
                if tools:
                    response = self.client.chat.completions.create(
                        model="qwen-plus",
                        messages=messages,
                        tools=tools,
                        tool_choice="auto",
                        temperature=0.1,
                        max_tokens=3000,
                        timeout=90
                    )
                else:
                    response = self.client.chat.completions.create(
                        model="qwen-plus",
                        messages=messages,
                        temperature=0.1,
                        max_tokens=3000,
                        timeout=90
                    )
                
                message = response.choices[0].message
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if message.tool_calls:
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    for tool_call in message.tool_calls:
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)
                        
                        if status_callback:
                            await status_callback(f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}")
                        
                        # æ‰§è¡Œå·¥å…·
                        tool_result = await self.tool_registry.execute_tool(
                            function_name, **function_args
                        )
                        
                        # æ·»åŠ å·¥å…·è°ƒç”¨åˆ°å¯¹è¯å†å²
                        self.conversation_history.append({
                            "role": "assistant",
                            "content": None,
                            "tool_calls": [{
                                "id": tool_call.id,
                                "type": "function",
                                "function": {
                                    "name": function_name,
                                    "arguments": tool_call.function.arguments
                                }
                            }]
                        })
                        
                        # æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                        self.conversation_history.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": json.dumps(tool_result.to_dict(), ensure_ascii=False)
                        })
                    
                    # ç»§ç»­ä¸‹ä¸€è½®åˆ†æ
                    continue
                
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆç­”æ¡ˆ
                    final_answer = message.content
                    
                    # æ·»åŠ åˆ°å¯¹è¯å†å²
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": final_answer
                    })
                    
                    if status_callback:
                        await status_callback("âœ… åˆ†æå®Œæˆ")
                    
                    return final_answer
                    
            except Exception as e:
                logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                if status_callback:
                    await status_callback(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
                return f"æŠ±æ­‰ï¼Œåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}ã€‚è¯·ç¨åé‡è¯•ã€‚"
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if status_callback:
            await status_callback("âš ï¸ è¾¾åˆ°æœ€å¤§åˆ†æè½®æ•°")
        
        return "åˆ†æè¿‡ç¨‹è¾ƒä¸ºå¤æ‚ï¼Œå·²è¾¾åˆ°æœ€å¤§å¤„ç†è½®æ•°ã€‚å¦‚éœ€æ›´æ·±å…¥çš„åˆ†æï¼Œè¯·å°†é—®é¢˜åˆ†è§£ä¸ºæ›´å…·ä½“çš„å­é—®é¢˜ã€‚"
    
    async def process_query_stream(self, user_query: str) -> AsyncGenerator[str, None]:
        """æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        start_time = time.time()
        
        yield "ğŸš€ å¯åŠ¨ä¸“å®¶åˆ†æç³»ç»Ÿ...\n\n"
        
        # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "user",
            "content": user_query
        })
        
        iteration = 0
        
        while iteration < self.max_iterations:
            # æ£€æŸ¥è¶…æ—¶
            if time.time() - start_time > self.max_processing_time:
                yield "â° å¤„ç†è¶…æ—¶ï¼Œè¿”å›å½“å‰ç»“æœ\n"
                break
            
            iteration += 1
            yield f"ğŸ¤” ç¬¬{iteration}è½®åˆ†æ...\n"
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": self.system_prompt}]
            messages.extend(self.conversation_history)
            
            # è·å–å·¥å…·å®šä¹‰
            tools = self.tool_registry.get_openai_tools()
            
            try:
                # è°ƒç”¨LLM
                if tools:
                    response = self.client.chat.completions.create(
                        model="qwen-plus",
                        messages=messages,
                        tools=tools,
                        tool_choice="auto",
                        temperature=0.1,
                        max_tokens=3000,
                        timeout=90,
                        stream=True
                    )
                else:
                    response = self.client.chat.completions.create(
                        model="qwen-plus",
                        messages=messages,
                        temperature=0.1,
                        max_tokens=3000,
                        timeout=90,
                        stream=True
                    )
                
                # å¤„ç†æµå¼å“åº”
                accumulated_content = ""
                tool_calls_buffer = []
                
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        accumulated_content += content
                        yield content
                    
                    if chunk.choices[0].delta.tool_calls:
                        tool_calls_buffer.extend(chunk.choices[0].delta.tool_calls)
                
                # å¤„ç†å·¥å…·è°ƒç”¨
                if tool_calls_buffer:
                    yield "\n\n"
                    for tool_call in tool_calls_buffer:
                        if tool_call.function:
                            function_name = tool_call.function.name
                            function_args = json.loads(tool_call.function.arguments)
                            
                            yield f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}\n"
                            
                            # æ‰§è¡Œå·¥å…·
                            tool_result = await self.tool_registry.execute_tool(
                                function_name, **function_args
                            )
                            
                            # æ·»åŠ å·¥å…·è°ƒç”¨åˆ°å¯¹è¯å†å²
                            self.conversation_history.append({
                                "role": "assistant",
                                "content": None,
                                "tool_calls": [{
                                    "id": tool_call.id,
                                    "type": "function",
                                    "function": {
                                        "name": function_name,
                                        "arguments": tool_call.function.arguments
                                    }
                                }]
                            })
                            
                            # æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                            self.conversation_history.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": json.dumps(tool_result.to_dict(), ensure_ascii=False)
                            })
                    
                    yield "\n"
                    # ç»§ç»­ä¸‹ä¸€è½®åˆ†æ
                    continue
                
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå®Œæˆåˆ†æ
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": accumulated_content
                    })
                    
                    yield "\n\nâœ… åˆ†æå®Œæˆ"
                    return
                    
            except Exception as e:
                logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                yield f"\nâŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}\nè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚"
                return
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        yield "\nâš ï¸ è¾¾åˆ°æœ€å¤§åˆ†æè½®æ•°\nåˆ†æè¿‡ç¨‹è¾ƒä¸ºå¤æ‚ï¼Œå¦‚éœ€æ›´æ·±å…¥çš„åˆ†æï¼Œè¯·å°†é—®é¢˜åˆ†è§£ä¸ºæ›´å…·ä½“çš„å­é—®é¢˜ã€‚"

    def get_conversation_summary(self) -> str:
        """è·å–å¯¹è¯æ‘˜è¦"""
        if not self.conversation_history:
            return "æš‚æ— å¯¹è¯è®°å½•"
        
        user_messages = [msg for msg in self.conversation_history if msg["role"] == "user"]
        assistant_messages = [msg for msg in self.conversation_history if msg["role"] == "assistant" and msg.get("content")]
        tool_calls = [msg for msg in self.conversation_history if msg["role"] == "assistant" and msg.get("tool_calls")]
        
        return f"""## å¯¹è¯æ‘˜è¦
- ç”¨æˆ·æé—®: {len(user_messages)} æ¬¡
- åŠ©æ‰‹å›å¤: {len(assistant_messages)} æ¬¡  
- å·¥å…·è°ƒç”¨: {len(tool_calls)} æ¬¡
- å±•æ¿ID: {self.board_id}

### æœ€è¿‘è¯é¢˜
{user_messages[-1]["content"] if user_messages else "æ— "}"""

    def clear_conversation(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        logger.info(f"å·²æ¸…ç©ºå¯¹è¯å†å²: {self.session_id}")

    def export_conversation(self) -> Dict[str, Any]:
        """å¯¼å‡ºå¯¹è¯è®°å½•"""
        return {
            "session_id": self.session_id,
            "board_id": self.board_id,
            "conversation_history": self.conversation_history,
            "exported_at": datetime.now().isoformat()
        }

class MCPExpertManager:
    """MCPä¸“å®¶ç³»ç»Ÿç®¡ç†å™¨"""
    
    def __init__(self):
        self.experts: Dict[str, MCPExpert] = {}
        self.created_at = datetime.now().isoformat()
    
    def get_expert(self, board_id: str) -> MCPExpert:
        """è·å–æˆ–åˆ›å»ºä¸“å®¶å®ä¾‹"""
        if board_id not in self.experts:
            self.experts[board_id] = MCPExpert(board_id)
            logger.info(f"ä¸ºå±•æ¿ {board_id} åˆ›å»ºæ–°çš„ä¸“å®¶å®ä¾‹")
        
        return self.experts[board_id]
    
    def remove_expert(self, board_id: str):
        """ç§»é™¤ä¸“å®¶å®ä¾‹"""
        if board_id in self.experts:
            del self.experts[board_id]
            logger.info(f"å·²ç§»é™¤å±•æ¿ {board_id} çš„ä¸“å®¶å®ä¾‹")
    
    def get_all_experts(self) -> Dict[str, MCPExpert]:
        """è·å–æ‰€æœ‰ä¸“å®¶å®ä¾‹"""
        return self.experts.copy()
    
    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_experts": len(self.experts),
            "active_boards": list(self.experts.keys()),
            "manager_created_at": self.created_at,
            "current_time": datetime.now().isoformat()
        }

# å…¨å±€ä¸“å®¶ç®¡ç†å™¨å®ä¾‹
expert_manager = MCPExpertManager() 